## Advanced image alignment

Diverse weather and lighting conditions create significant differences in visual attributes between haze-free and hazy images, posing challenges for their alignment. To address this, a keypoint matching technique is utilized to align haze-free and hazy images. Synthetic-haze images are additionally introduced, which are generated by referencing using the atmospheric scattering model and depth maps from **[Monodepth2](https://github.com/nianticlabs/monodepth2)**. Introducing synthetic-haze images can enhance the accuracy of matching between haze-free and hazy images by reducing color disparities.

### Step1: 

Use the **[Monodepth2](https://github.com/nianticlabs/monodepth2)** to generate depth maps of haze-free images. This paper chooses the [mono+stereo_1024x320](https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono%2Bstereo_1024x320.zip) pre-trained model.

### Step 2:

Execute *get_syn_img.ipynb* to create synthetic-haze images.

### Step 3:

**[SuperPoint](https://github.com/eric-yyjau/pytorch-superpoint)** is utilized as the feature extractor, and **[LightGlue](https://github.com/cvg/LightGlue)** is employed as the feature matcher. By inputting pairs of synthetic-haze images and real-haze images, as well as pairs of haze-free images and real-haze images, we obtain two sets of keypoints. These sets need to be merged before generating a well-aligned hazy image with the haze-free image using *get_wrapped_img.ipynb*.

### Calculate PCK value

Please download the **[keypoints (.pkl file)](https://drive.google.com/drive/folders/1JuX6v4qOJYRtAcIqiyFA-8HuIMbE8rRl?usp=drive_link)** extracted using the **[LoFTR](https://github.com/zju3dv/LoFTR.git)** and place them in the *keypoints* folder. You can then calculate the PCK value by running *get_pck.ipynb*. Alternatively, you can place *get_keypoints.py* into the *LoFTR* folder to generate the keypoints (.pkl file) for your data.
